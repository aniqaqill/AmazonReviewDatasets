{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aniqa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aniqa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aniqa\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>great</td>\n",
       "      <td>98076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>good</td>\n",
       "      <td>47254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>fun</td>\n",
       "      <td>24334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>love</td>\n",
       "      <td>24133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>quality</td>\n",
       "      <td>23929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>perfect</td>\n",
       "      <td>20141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>cute</td>\n",
       "      <td>18401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>nice</td>\n",
       "      <td>18056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>works</td>\n",
       "      <td>17816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>product</td>\n",
       "      <td>16979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>gift</td>\n",
       "      <td>13849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>price</td>\n",
       "      <td>11877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best</td>\n",
       "      <td>11752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>work</td>\n",
       "      <td>11269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awesome</td>\n",
       "      <td>11145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>easy</td>\n",
       "      <td>10674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>game</td>\n",
       "      <td>10495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>movie</td>\n",
       "      <td>10233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>well</td>\n",
       "      <td>9480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>kids</td>\n",
       "      <td>9475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword  frequency\n",
       "15      great      98076\n",
       "96       good      47254\n",
       "272       fun      24334\n",
       "74       love      24133\n",
       "323   quality      23929\n",
       "476   perfect      20141\n",
       "354      cute      18401\n",
       "93       nice      18056\n",
       "478     works      17816\n",
       "234   product      16979\n",
       "368      gift      13849\n",
       "167     price      11877\n",
       "1        best      11752\n",
       "328      work      11269\n",
       "0     awesome      11145\n",
       "514      easy      10674\n",
       "2239     game      10495\n",
       "191     movie      10233\n",
       "533      well       9480\n",
       "378      kids       9475"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('merged_data.csv')\n",
    "\n",
    "# Clean the review text\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_review'] = df['review_title'].apply(clean_text)\n",
    "\n",
    "# Sentiment analysis\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "df['sentiment_score'] = df['cleaned_review'].apply(get_sentiment)\n",
    "df['sentiment'] = df['sentiment_score'].apply(lambda x: 'positive' if x >= 0.05 else ('negative' if x <= -0.05 else 'neutral'))\n",
    "\n",
    "# Keyword frequency analysis\n",
    "tokens = [word_tokenize(text) for text in df['cleaned_review']]\n",
    "all_tokens = [token for sublist in tokens for token in sublist]\n",
    "freq_dist = Counter(all_tokens)\n",
    "freq_df = pd.DataFrame(freq_dist.items(), columns=['keyword', 'frequency']).sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "df.to_csv('sentiment_analysis.csv', index=False)\n",
    "freq_df.to_csv('keyword_frequency.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the sentiment analysis DataFrame\n",
    "df[['cleaned_review', 'sentiment_score', 'sentiment']].head()\n",
    "\n",
    "# Display the top 20 keywords\n",
    "freq_df.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerged_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df2[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparent_asin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_title\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m----> 6\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_review\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[43mclean_text\u001b[49m)\n\u001b[0;32m      7\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_review\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(word_tokenize)\n\u001b[0;32m      8\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyword\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(Counter)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_text' is not defined"
     ]
    }
   ],
   "source": [
    "#exsport the csv of keyword frequency and its pasrent_asin involve?\n",
    "import pandas as pd\n",
    "df2 = pd.read_csv('merged_data.csv')\n",
    "\n",
    "df2 = df2[['parent_asin', 'review_title']]\n",
    "df2['cleaned_review'] = df2['review_title'].apply(clean_text)\n",
    "df2['tokens'] = df2['cleaned_review'].apply(word_tokenize)\n",
    "df2['keyword'] = df2['tokens'].apply(Counter)\n",
    "df2['keyword'] = df2['keyword'].apply(lambda x: [word for word in x if freq_dist[word] > 1])\n",
    "df2 = df2.explode('keyword')\n",
    "df2 = df2.groupby(['parent_asin', 'keyword']).size().reset_index(name='frequency')\n",
    "df2 = df2.sort_values(by='frequency', ascending=False)\n",
    "# df2.to_csv('keyword_frequency_by_asin.csv', index=False)\n",
    "df2.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
